# -*- coding: utf-8 -*-
"""Insurance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d_3r-ivtIqn7qjPyhxCISKCvy-3SKe2M
"""

#Libraries imported
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from array import array

df=pd.read_csv("Round2-DataScience-HomeworkData.csv")

"""Details about the dataset"""

df.shape

df.dtypes

"""Getting summary of statistics for each features ."""

df.describe()

"""*DATA CLEANING *

Handling Errors and Missing values
"""

df.isnull()

df.isnull().sum()

df['EDCost'].unique()

df['IPCost'].unique()

df['IPCount'].unique()

df['EDCount'].unique()

df["Voluntary"]

pd.unique(df[['Voluntary','churned']].values.ravel())

"""To know that there are no churned value for nan in Voluntary Column"""

group = df.groupby('Voluntary')
df2 = group.apply(lambda x: x['churned'].unique())
df2

df[['Voluntary']] = df[['Voluntary']].fillna(value='NA')

df

df=df.drop(['Voluntary'], axis=1)

df[['EDCost','IPCost','IPCount','EDCount']] = df[['EDCost','IPCost','IPCount','EDCount']].fillna(value=0)

df.isnull().sum()

"""**DATA TRANSFORMATION**"""

df.dtypes

df.head(5)

"""Visualization :
Count of Churns in each state
"""

states= df[df['churned']>0]

states

visualization = df[['churned','State']]
visualization

st=visualization.groupby('State').count()[['churned']]
st.columns

"""**Encoding categorical variables **"""

from sklearn.preprocessing import LabelEncoder
from sklearn import preprocessing

# creating instance of labelencoder
labelencoder = LabelEncoder()

label_encoder = preprocessing.LabelEncoder()
df['LOB']= label_encoder.fit_transform(df['LOB']) 
df['State']= label_encoder.fit_transform(df['State']) 
df

df=df.drop(['MEMBER_ID'], axis=1)

df

"""**Visualization for analysis**

Calculating the count of churns in each and every state
"""



"""**Risk score prediction**"""

from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestRegressor

y = df['churned']
X=df.drop(['churned'], axis=1)

X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, random_state=42)

log_regression=LogisticRegression(multi_class="auto",solver="lbfgs",C=1.0,max_iter=100,random_state=42)
log_regression.fit(X_train,y_train)
pred_log=log_regression.predict(X_test)
acc_score=accuracy_score(y_test,pred_log)
print(acc_score)

from sklearn.model_selection import cross_val_score

scores = cross_val_score(log_regression, X_train, y_train, cv=10)
print('Cross-Validation Accuracy Scores', scores)

nn_classifier=MLPClassifier(hidden_layer_sizes=(50,2),max_iter=100,verbose=True,solver='adam',n_iter_no_change=10,activation='identity')
nn_classifier.fit(X_train,y_train)
pred_random=nn_classifier.predict(X_test)
acc_score=accuracy_score(y_test,pred_random)
print(acc_score)